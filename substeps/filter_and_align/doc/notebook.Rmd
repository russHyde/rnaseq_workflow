---
title: "Notebook for the `filter_and_align` substep"
output:
  html_document: default
  pdf_document:
    df_print: kable
    fig_caption: yes
    fig_height: 7
    fig_width: 7
    includes:
      in_header: header.tex
    latex_engine: xelatex
    number_sections: yes
date: '`r format(Sys.time(), "%Y-%m-%d")`'
urlcolor: blue
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

show_setup <- FALSE
show_functions <- FALSE
show_figure_code <- FALSE
show_file_writes <- FALSE
show_code <- TRUE
```

# Environment

```{r, echo = !show_setup}
# To see the environment-setup code, recompile with `show_setup = TRUE`
```

```{r, echo = show_setup}
library(here)
```

```{r, echo = show_setup}
pkgs <- c(
  # CRAN
  "dplyr",
  #  "forcats",
  "ggplot2",
  "magrittr",
  "plotly",
  #  "purrr",
  "readr",
  #  "stringr",
  "tibble",
  #  "tidyr",

  # Bioconductor
  #  "biomaRt",
  #  "cqn",
  #  "edgeR",

  # My packages
  "reeq"
  #  "s3tree"
)

for (pkg in pkgs) {
  suppressPackageStartupMessages(
    library(pkg, character.only = TRUE)
  )
}
```

```{r, echo = show_setup}
# For storing intermediate results that will be used in the text
sketches <- list()

# For storing results that will be presented in the Executive Summary
gallery <- list()
```

# Functions

```{r, echo = !show_functions}
# To see the function definitions, recompile with `show_functions = TRUE`
```

## Data Import

```{r, echo = show_functions}
define_file_map <- function(dirs, seq_files) {
  stopifnot("counts" %in% names(dirs))
  stopifnot(
    all(c("study_id", "sample_id", "run_id", "lane_id") %in% names(seq_files))
  )
  tibble::tibble(
    study_id = seq_files$study_id,
    sample_id = seq_files$sample_id,
    run_id = seq_files$run_id,
    lane_id = seq_files$lane_id
  ) %>%
    dplyr::mutate(
      counts = file.path(
        dirs$counts, study_id, sample_id,
        paste0(run_id, "_", lane_id, ".fcount.short")
      )
    )
}
```


## Data manipulation

### Feature Counts

```{r, echo = show_functions}
get_feature_counts_by_lane <- function(file_map) {
  # TODO: fix the workflow so that lanes are merged prior to featureCounts call
  # Then replace any call to get_feature_counts_by_lane with
  # `reeq::read_feature_counts`

  stopifnot(
    all(c("counts", "sample_id", "run_id", "lane_id") %in% colnames(file_map))
  )

  purrr::pmap_dfr(
    file_map[c("counts", "sample_id", "run_id", "lane_id")],
    function(
                 counts, sample_id, run_id, lane_id) {
      fcounts <- reeq:::read_single_feature_counts_file(counts)
      names(fcounts)[3] <- "count"
      sample_details <- tibble::tibble(
        sample_id = sample_id, run_id = run_id, lane_id = lane_id
      )
      cbind(sample_details, fcounts)
    }
  )
}
```

```{r}
merge_feature_counts_over_lanes <- function(feature_counts_by_lane) {
  feature_counts_by_lane %>%
    dplyr::group_by(sample_id, run_id, feature_id, length) %>%
    dplyr::summarise(count = sum(count)) %>%
    # (sample_id, run_id, feature_id, length, count)
    # want: (feature_id, length, sample_1, sample_2, ...)
    dplyr::ungroup() %>%
    dplyr::transmute(
      feature_id, length,
      sample_id = make.names(paste(sample_id, run_id, sep = "__")),
      count
    ) %>%
    tidyr::spread(sample_id, count)
}
```

# Directories

All results constructed by this notebook are stored in
`<this_substep>/results/notebook_pdf_output/`

```{r}
dirs <- list()
```

```{r}
dirs <- list(
  config = here("conf"),
  data = here("data"),
  results = here("results", "notebook_pdf_output")
)

dirs$counts <- file.path(dirs$data, "job", "align")
```

```{r}
for (d in dirs) {
  if (!dir.exists(d)) {
    dir.create(d, recursive = TRUE)
  }
}
```

# Data

## Project-specific data

External files and study information were imported.

The sequencing files are referred to by several IDs.

- `study_id` - the EBI ID for the whole dataset

- `sample_id` - the ID for an experimental sample (a specific treatment in a
specific patient)

- `run_id` - the ID for a sequencing sample (in this specific experiment there
is a one-one relationship between `run_id` and `sample_id`)

- `lane_id` - which lane was a given sequencing sample ran on

```{r}
seq_files <- readr::read_tsv(
  file.path(dirs$config, "sequencing_samples.tsv"),
  col_types = cols()
)
```

The sequencing data was aligned and the transcriptome assignments were
summarised with `featureCounts`. The filepaths for the counted data were
constructed:

```{r}
file_map <- define_file_map(dirs, seq_files)
```

\blandscape
```{r}
# Example of the sequencing files and their source locations.
head(seq_files)
```

```{r}
# Position of the featureCount-summarised data for (a subset of) the
# samples
head(file_map)
```
\elandscape

<!-- ====================================================================== -->

# Import sample-specific information

<!-- ====================================================================== -->

## Feature-Counts

The count data for each lane was read in and summed together to generate the
count data for each sequencing sample.


```{r}
feature_counts_by_lane <- get_feature_counts_by_lane(file_map)
```

```{r}
feature_counts <- merge_feature_counts_over_lanes(feature_counts_by_lane)
```

```{r}
p <- feature_counts_by_lane %>%
  group_by(feature_id) %>%
  summarise(
    mu = mean(log2(16 + count)), sd = sd(log2(16 + count))
  ) %>%
  ggplot(aes(x = mu, y = sd)) +
  geom_point(aes(text = feature_id))
```

```{r}
ggplotly(p)
```

```{r}
head(feature_counts)
```
